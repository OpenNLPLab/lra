# _target_: models.sequence.SequenceModel
_name_: model
layer:
  - _name_: flash_attn
    s: ${model.flash_s}
    eps: 1e-5
    max_position_embeddings: ${model.flash_max_position_embed}

flash_s: 128
flash_max_position_embed: 512

flash_linear_s: 0
flash_linear_max_position_embeddings: 0
lg_local_heads: 0
lg_linear_heads: 0
lg_local_chunk_size: 0
ls_attn_heads: 0
ls_attn_window_size: 0
ls_attn_max_seq_len: 0
performer_heads: 0
performer_approx_attn_dim: 0
use_softmax: true
act_fun: 1+elu
cosformer_heads: 0 
cosformer_max_length: 0
linformer_max_seq_len: 0
reformer_max_seq_len: 0

residual: R
dropout: 0.1
encoder:
  _name_: position
  dropout: 0.1
# init:
#   init: normal  # Parameter initializer to use
#   init_range: 0.1  # Parameters initialized by U(-init_range, init_range)
#   init_std: 0.02  # Parameters initialized by N(0, init_std)